{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colornet_train.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg0kFYlN-E8x",
        "colab_type": "code",
        "outputId": "da1fb6d8-29cd-4625-c482-ab4b219e31b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Load the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "directory = '/content/gdrive/My Drive/ColorNetData/'\n",
        "train_directory = directory + 'Train/'\n",
        "test_directory = directory + 'Test/'\n",
        "\n",
        "# Load all the required data\n",
        "from pickle import load\n",
        "train_image_encoding = load(open(directory + 'train_image_encoding.p', 'rb'))\n",
        "test_image_encoding = load(open(directory + 'test_image_encoding.p', 'rb'))\n",
        "model = load(open(directory + 'final_model.p', 'rb'))\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
        "model.load_weights(directory + 'weights.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MDYxW_-_CDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the data generator\n",
        "def data_generator(batch_size=32):\n",
        "  import numpy as np\n",
        "  from skimage.color import rgb2lab, lab2rgb\n",
        "  from keras.preprocessing.image import load_img, img_to_array\n",
        "  encoder_input = list()\n",
        "  embedding_input = list()\n",
        "  model_output = list()\n",
        "  from itertools import cycle\n",
        "  for name, embedding in cycle(train_image_encoding.items()):\n",
        "    # Encoded image input\n",
        "    image = np.array(img_to_array(load_img(train_directory + name, target_size=(256, 256))), dtype=float)\n",
        "    encoded_image = rgb2lab(1.0/255*image)[:, :, 0]\n",
        "    encoded_image = encoded_image.reshape(encoded_image.shape[0], encoded_image.shape[1], 1)\n",
        "    # Output image\n",
        "    output_image = rgb2lab(1.0/255*image)[:, :, 1:]\n",
        "    output_image = output_image/128\n",
        "    output_image = output_image.reshape(output_image.shape[0], output_image.shape[1], 2)\n",
        "    # Add to return\n",
        "    encoder_input.append(encoded_image)\n",
        "    embedding_input.append(embedding.flatten())\n",
        "    model_output.append(output_image)\n",
        "    \n",
        "    if len(model_output) >= batch_size:\n",
        "      encoder_input = np.asarray(encoder_input)\n",
        "      embedding_input = np.asarray(embedding_input)\n",
        "      model_output = np.asarray(model_output)\n",
        "      yield [[encoder_input, embedding_input], model_output]\n",
        "      encoder_input = list()\n",
        "      embedding_input = list()\n",
        "      model_output = list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M0p4BrsA7kg",
        "colab_type": "code",
        "outputId": "3a51cc61-f2f5-47c5-b90a-399a28fac728",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Execute this to train\n",
        "batch_size = 32\n",
        "nb_epoch = 1\n",
        "steps_per_epoch = int(len(train_image_encoding)/batch_size)\n",
        "model.fit_generator(data_generator(batch_size), nb_epoch=nb_epoch, verbose=1, steps_per_epoch=steps_per_epoch)\n",
        "model.save_weights(directory + 'weights.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., verbose=1, steps_per_epoch=262, epochs=1)`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "  2/262 [..............................] - ETA: 55:45 - loss: 0.0122 - mean_squared_error: 0.0122  "
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}